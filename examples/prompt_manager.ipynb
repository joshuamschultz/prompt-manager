{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Manager End-to-End Test\n",
    "\n",
    "This notebook provides a comprehensive test of the prompt manager functionality:\n",
    "1. Load prompts from YAML\n",
    "2. Render prompts with variables\n",
    "3. Make Anthropic API calls\n",
    "4. Validate responses\n",
    "\n",
    "**Prerequisites:**\n",
    "- Add your Anthropic API key to `.env` file in the project root\n",
    "- Install required dependencies: `pip install anthropic python-dotenv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import anthropic\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Imported PromptManager\n"
     ]
    }
   ],
   "source": [
    "# Add src to path to import prompt_manager\n",
    "project_root = Path.cwd().parent\n",
    "src_path = project_root / \"src\"\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "from prompt_manager import PromptManager\n",
    "\n",
    "print(\"\u2713 Imported PromptManager\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 API key loaded (length: 108)\n"
     ]
    }
   ],
   "source": [
    "# Load .env file from project root\n",
    "env_path = project_root / \".env\"\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# Verify API key is loaded\n",
    "api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "if api_key:\n",
    "    print(f\"\u2713 API key loaded (length: {len(api_key)})\")\n",
    "else:\n",
    "    print(\"\u2717 API key not found in .env file\")\n",
    "    print(f\"  Expected location: {env_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for environments without top-level await support\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "# Allow nested event loops (for Jupyter)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def run_async(coro):\n",
    "    \"\"\"Helper to run async code in sync context.\"\"\"\n",
    "    loop = asyncio.get_event_loop()\n",
    "    return loop.run_until_complete(coro)\n",
    "\n",
    "print(\"\u2713 Async helper configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Prompt Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Prompt manager initialized with simplified API\n"
     ]
    }
   ],
   "source": [
    "# Create prompt manager using simplified API\n",
    "# This automatically creates storage and registry with sensible defaults\n",
    "manager = run_async(PromptManager.create(\n",
    "    prompt_dir=\"./prompts\",  # Directory for storing prompts\n",
    "    auto_load_yaml=True,      # Automatically load YAML files\n",
    "))\n",
    "\n",
    "print(\"\u2713 Prompt manager initialized with simplified API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Prompts from YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'coroutine' object has no attribute 'list_prompts'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Verify YAML prompts were auto-loaded\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m prompts = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mmanager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_prompts\u001b[49m()\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\u2713 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(prompts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m prompts loaded automatically from YAML files\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Show what was loaded\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'coroutine' object has no attribute 'list_prompts'"
     ]
    }
   ],
   "source": [
    "# Verify YAML prompts were auto-loaded\n",
    "prompts = run_async(manager.list_prompts())\n",
    "print(f\"\u2713 {len(prompts)} prompts loaded automatically from YAML files\")\n",
    "\n",
    "# Show what was loaded\n",
    "for prompt in prompts:\n",
    "    print(f\"  - {prompt.id} v{prompt.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. List Available Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'coroutine' object has no attribute 'list_prompts'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# List all prompts\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m prompts = \u001b[43mmanager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_prompts\u001b[49m()\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#print(f\"Available prompts ({len(prompts)}):\")  \u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[31mAttributeError\u001b[39m: 'coroutine' object has no attribute 'list_prompts'"
     ]
    }
   ],
   "source": [
    "# List all prompts\n",
    "prompts = run_async(manager.list_prompts())\n",
    "\n",
    "#print(f\"Available prompts ({len(prompts)}):\")  \n",
    "print()\n",
    "for prompt in prompts:\n",
    "    print(f\"ID: {prompt.id}\")\n",
    "    print(f\"  Version: {prompt.version}\")\n",
    "    print(f\"  Format: {prompt.format.value}\")\n",
    "    print(f\"  Status: {prompt.status.value}\")\n",
    "    print(f\"  Description: {prompt.metadata.description if prompt.metadata else 'N/A'}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Render a Text Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render a simple text prompt\n",
    "prompt_id = \"greeting\"  # Adjust based on available prompts\n",
    "variables = {\n",
    "    \"name\": \"Alice\",\n",
    "    \"language\": \"English\"\n",
    "}\n",
    "\n",
    "rendered = manager.render(prompt_id, variables=variables)\n",
    "\n",
    "print(f\"Rendered prompt '{prompt_id}':\")\n",
    "print(\"-\" * 50)\n",
    "print(rendered)\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Anthropic Integration - Text Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Anthropic client\n",
    "client = anthropic.Anthropic(api_key=api_key)\n",
    "\n",
    "# Get the prompt using manager\n",
    "prompt = run_async(manager.get_prompt(\"greeting\"))\n",
    "\n",
    "# Create integration\n",
    "integration = AnthropicIntegration(template_engine=manager._template_engine)\n",
    "\n",
    "# Convert prompt to Anthropic format\n",
    "messages = integration.convert(prompt, variables=variables)\n",
    "\n",
    "print(\"Converted messages for Anthropic:\")\n",
    "print(json.dumps(messages, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make API call\n",
    "response = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    max_tokens=1024,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(\"Response from Anthropic:\")\n",
    "print(\"-\" * 50)\n",
    "print(response.content[0].text)\n",
    "print(\"-\" * 50)\n",
    "print(f\"\\nTokens used: {response.usage.input_tokens} input, {response.usage.output_tokens} output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Chat Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a chat format prompt if available\n",
    "all_prompts = run_async(manager.list_prompts())\n",
    "chat_prompts = [p for p in all_prompts if p.format.value == \"chat\"]\n",
    "\n",
    "if chat_prompts:\n",
    "    chat_prompt_id = chat_prompts[0].id\n",
    "    print(f\"Testing chat prompt: {chat_prompt_id}\")\n",
    "    \n",
    "    # Adjust variables based on the prompt\n",
    "    chat_variables = {\n",
    "        \"user_message\": \"I need help with my order #12345\",\n",
    "        \"user_name\": \"Bob\"\n",
    "    }\n",
    "    \n",
    "    # Get and convert prompt\n",
    "    chat_prompt = run_async(manager.get_prompt(chat_prompt_id))\n",
    "    chat_messages = integration.convert(chat_prompt, variables=chat_variables)\n",
    "    \n",
    "    print(\"\\nChat messages:\")\n",
    "    print(json.dumps(chat_messages, indent=2))\n",
    "else:\n",
    "    print(\"No chat prompts found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make API call with chat prompt\n",
    "if chat_prompts:\n",
    "    chat_response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        max_tokens=1024,\n",
    "        messages=chat_messages\n",
    "    )\n",
    "    \n",
    "    print(\"Chat response from Anthropic:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(chat_response.content[0].text)\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"\\nTokens used: {chat_response.usage.input_tokens} input, {chat_response.usage.output_tokens} output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Schema Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test prompt with output schema\n",
    "from prompt_manager.core.models import Prompt, PromptFormat, PromptStatus, PromptTemplate\n",
    "\n",
    "# Create a simple extraction prompt\n",
    "extraction_prompt = Prompt(\n",
    "    id=\"extract_info\",\n",
    "    version=\"1.0.0\",\n",
    "    format=PromptFormat.TEXT,\n",
    "    status=PromptStatus.ACTIVE,\n",
    "    template=PromptTemplate(\n",
    "        content=\"Extract the name and email from this text: {{text}}\\n\\nReturn as JSON with 'name' and 'email' fields.\",\n",
    "        variables=[\"text\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Register the prompt\n",
    "manager.create_prompt(extraction_prompt)\n",
    "print(\"\u2713 Created extraction prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render and call Anthropic\n",
    "extraction_vars = {\n",
    "    \"text\": \"Contact John Smith at john.smith@example.com for more information.\"\n",
    "}\n",
    "\n",
    "extraction_prompt = run_async(manager.get_prompt(\"extract_info\"))\n",
    "extraction_messages = integration.convert(\n",
    "    extraction_prompt,\n",
    "    variables=extraction_vars\n",
    ")\n",
    "\n",
    "extraction_response = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    max_tokens=256,\n",
    "    messages=extraction_messages\n",
    ")\n",
    "\n",
    "result_text = extraction_response.content[0].text\n",
    "print(\"Extraction result:\")\n",
    "print(result_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse and validate JSON response\n",
    "try:\n",
    "    # Extract JSON from response (handle markdown code blocks)\n",
    "    import re\n",
    "    \n",
    "    # Try to find JSON in code blocks first\n",
    "    json_match = re.search(r'```json\\s*(.+?)\\s*```', result_text, re.DOTALL)\n",
    "    if json_match:\n",
    "        json_str = json_match.group(1)\n",
    "    else:\n",
    "        # Try to find raw JSON\n",
    "        json_match = re.search(r'\\{.+\\}', result_text, re.DOTALL)\n",
    "        if json_match:\n",
    "            json_str = json_match.group(0)\n",
    "        else:\n",
    "            json_str = result_text\n",
    "    \n",
    "    parsed_result = json.loads(json_str)\n",
    "    \n",
    "    print(\"\u2713 Successfully parsed JSON:\")\n",
    "    print(json.dumps(parsed_result, indent=2))\n",
    "    \n",
    "    # Validate structure\n",
    "    required_fields = [\"name\", \"email\"]\n",
    "    missing_fields = [f for f in required_fields if f not in parsed_result]\n",
    "    \n",
    "    if missing_fields:\n",
    "        print(f\"\\n\u2717 Missing required fields: {missing_fields}\")\n",
    "    else:\n",
    "        print(\"\\n\u2713 All required fields present\")\n",
    "        print(f\"  Name: {parsed_result['name']}\")\n",
    "        print(f\"  Email: {parsed_result['email']}\")\n",
    "        \n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"\u2717 Failed to parse JSON: {e}\")\n",
    "    print(f\"  Response text: {result_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PROMPT MANAGER TEST SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"\u2713 Environment setup\")\n",
    "print(\"\u2713 Prompt manager initialized\")\n",
    "print(f\"\u2713 Loaded {count} prompts from YAML\")\n",
    "print(\"\u2713 Rendered text prompt\")\n",
    "print(\"\u2713 Anthropic integration working\")\n",
    "print(\"\u2713 Text prompt API call successful\")\n",
    "if chat_prompts:\n",
    "    print(\"\u2713 Chat prompt API call successful\")\n",
    "print(\"\u2713 JSON extraction and validation working\")\n",
    "print()\n",
    "print(\"All tests passed!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}